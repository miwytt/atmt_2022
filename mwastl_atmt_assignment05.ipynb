{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj5AdVG0oyhcHIi9GFhwzN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miwytt/atmt_2022/blob/assignment05/mwastl_atmt_assignment05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment preparation\n",
        "\n"
      ],
      "metadata": {
        "id": "neKlGawp-R_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vw7-Kxex9uM5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUQU28Jo90zg",
        "outputId": "de0d2211-bd44-43d9-f7c4-49f319e3f4a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-rr56x_9z\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-rr56x_9z\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.6.0 sacrebleu-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PxRPldT91PJ",
        "outputId": "488d0de1-7fda-42a6-e977-8904041eff63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU(s)\n",
        "if torch.cuda.is_available():       \n",
        "    cuda = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    cuda = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GUkZFoX97HP",
        "outputId": "fa9974de-5cc2-4165-b683-035502d38e50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "pF3gkwcJ7-OJ",
        "outputId": "5f7f9c91-0e00-4cfb-845d-1e3ea08970f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/atmt/assignment05\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxCcDkoZ-BRG",
        "outputId": "64e53d4d-5ddb-4659-ce4e-11de091a7940"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/atmt/assignment05\n",
            " \u001b[0m\u001b[01;34matmt_2022\u001b[0m/\n",
            "'Bildschirmfoto 2022-12-11 um 08.48.28.png'\n",
            " cding_mwastl_atmt_assignment05_Q3_2.gsheet\n",
            " cding_mwastl_atmt_assignment05_Q3.gsheet\n",
            " mwastl_atmt_assignment05.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cloning the repository \n",
        "!git clone --branch assignment05 https://github.com/miwytt/atmt_2022/\n",
        "!git checkout assignment05\n",
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYvKB-1a-GkZ",
        "outputId": "9956e3ef-9016-4744-a081-e67cb13f5a52"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'atmt_2022' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd atmt_2022/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhjfKbL7-QOV",
        "outputId": "b9e97fce-f855-4b0e-bb18-029b96157886"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/atmt/assignment05/atmt_2022\n",
            "\u001b[0m\u001b[01;34massignments\u001b[0m/  \u001b[01;34mmoses_scripts\u001b[0m/  README.md         \u001b[01;34mseq2seq\u001b[0m/  translate_beam.py\n",
            "\u001b[01;34mdata\u001b[0m/         preprocess.py   requirements.txt  \u001b[01;34mshare\u001b[0m/    translate.py\n",
            "LICENSE       \u001b[01;34m__pycache__\u001b[0m/    \u001b[01;34mscripts\u001b[0m/          train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Experimenting with Beam Search"
      ],
      "metadata": {
        "id": "eKKsG-dW-YoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with Beam Sizes\n",
        "\n",
        "Beam sizes: 1 <= k <= 25.\n",
        "\n",
        "Baseline model: assignments/03/baseline/checkpoints (hallerp version)"
      ],
      "metadata": {
        "id": "gMJZgc5e-nDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 26):\n",
        "  # run inference on test set\n",
        "  !python translate_beam.py \\\n",
        "      --data data/en-fr/prepared \\\n",
        "      --dicts data/en-fr/prepared \\\n",
        "      --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt \\\n",
        "      --output assignments/05/squared_regularizer/translations.txt \\\n",
        "      --cuda True \\\n",
        "      --beam-size {i}\n",
        "\n",
        "  # Postprocess model translations\n",
        "  !bash scripts/postprocess.sh \\\n",
        "      assignments/05/beam_sizes/translations.txt \\\n",
        "      assignments/05/beam_sizes/translations.p.txt en\n",
        "\n",
        "  # Score with SacreBLEU\n",
        "  !cat assignments/05/beam_sizes/translations.p.txt | sacrebleu data/en-fr/raw/test.en\n"
      ],
      "metadata": {
        "id": "QV7P6OnD-XkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Investigating the Diversity of Beam Search"
      ],
      "metadata": {
        "id": "QiedCTbk-7uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for g in [0.5, 1, 1.5]:\n",
        "  # run inference on test set\n",
        "  !python translate_beam.py \\\n",
        "      --data data/en-fr/prepared \\\n",
        "      --dicts data/en-fr/prepared \\\n",
        "      --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt \\\n",
        "      --output assignments/05/diversity/translations_div_{g}.txt \\\n",
        "      --cuda True \\\n",
        "      --n 3 \\\n",
        "      --gamma {g} \\\n",
        "\n",
        "\n",
        "  # Postprocess model translations\n",
        "  !bash scripts/postprocess.sh \\\n",
        "      assignments/05/diversity/translations_div_{g}.txt \\\n",
        "      assignments/05/diversity/translations_div_{g}.p.txt en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU0667la-_1n",
        "outputId": "cf1c4429-6606-4b26-9982-391b1e414f97"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-12-13 09:11:10] COMMAND: translate_beam.py --data data/en-fr/prepared --dicts data/en-fr/prepared --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt --output assignments/05/diversity/translations_div_0.5.txt --cuda True --n 3 --gamma 0.5\n",
            "[2022-12-13 09:11:10] Arguments: {'cuda': 'True', 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': None, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'log_file': None, 'save_dir': '/home/user/kew/HS2021/atmt/tests/assignment_03/baseline/checkpoints', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared', 'checkpoint_path': 'assignments/03/baseline/checkpoints/checkpoint_last.pt', 'output': 'assignments/05/diversity/translations_div_0.5.txt', 'max_len': 100, 'beam_size': 5, 'alpha': 0.0, 'lmbda': 0.0, 'n': 3, 'gamma': 0.5}\n",
            "[2022-12-13 09:11:10] Loaded a source dictionary (fr) with 4000 words\n",
            "[2022-12-13 09:11:10] Loaded a target dictionary (en) with 4000 words\n",
            "[2022-12-13 09:11:12] Loaded a model from checkpoint assignments/03/baseline/checkpoints/checkpoint_last.pt\n",
            "[2022-12-13 09:12:00] COMMAND: translate_beam.py --data data/en-fr/prepared --dicts data/en-fr/prepared --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt --output assignments/05/diversity/translations_div_1.txt --cuda True --n 3 --gamma 1\n",
            "[2022-12-13 09:12:00] Arguments: {'cuda': 'True', 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': None, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'log_file': None, 'save_dir': '/home/user/kew/HS2021/atmt/tests/assignment_03/baseline/checkpoints', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared', 'checkpoint_path': 'assignments/03/baseline/checkpoints/checkpoint_last.pt', 'output': 'assignments/05/diversity/translations_div_1.txt', 'max_len': 100, 'beam_size': 5, 'alpha': 0.0, 'lmbda': 0.0, 'n': 3, 'gamma': 1.0}\n",
            "[2022-12-13 09:12:00] Loaded a source dictionary (fr) with 4000 words\n",
            "[2022-12-13 09:12:00] Loaded a target dictionary (en) with 4000 words\n",
            "[2022-12-13 09:12:03] Loaded a model from checkpoint assignments/03/baseline/checkpoints/checkpoint_last.pt\n",
            "[2022-12-13 09:12:52] COMMAND: translate_beam.py --data data/en-fr/prepared --dicts data/en-fr/prepared --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt --output assignments/05/diversity/translations_div_1.5.txt --cuda True --n 3 --gamma 1.5\n",
            "[2022-12-13 09:12:52] Arguments: {'cuda': 'True', 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': None, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'log_file': None, 'save_dir': '/home/user/kew/HS2021/atmt/tests/assignment_03/baseline/checkpoints', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared', 'checkpoint_path': 'assignments/03/baseline/checkpoints/checkpoint_last.pt', 'output': 'assignments/05/diversity/translations_div_1.5.txt', 'max_len': 100, 'beam_size': 5, 'alpha': 0.0, 'lmbda': 0.0, 'n': 3, 'gamma': 1.5}\n",
            "[2022-12-13 09:12:52] Loaded a source dictionary (fr) with 4000 words\n",
            "[2022-12-13 09:12:52] Loaded a target dictionary (en) with 4000 words\n",
            "[2022-12-13 09:12:54] Loaded a model from checkpoint assignments/03/baseline/checkpoints/checkpoint_last.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference on test set\n",
        "!python translate_beam.py \\\n",
        "    --data data/en-fr/prepared \\\n",
        "    --dicts data/en-fr/prepared \\\n",
        "    --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt \\\n",
        "    --output assignments/05/diversity/translations_standard.txt \\\n",
        "    --cuda True \\\n",
        "    --n 3 \\\n",
        "\n",
        "\n",
        "# Postprocess model translations\n",
        "!bash scripts/postprocess.sh \\\n",
        "    assignments/05/diversity/translations_standard.txt \\\n",
        "    assignments/05/diversity/translations_standard.p.txt en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19GKINPcqWK1",
        "outputId": "e149980e-05be-4d61-bb3c-26b3ed530339"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-12-13 09:09:22] COMMAND: translate_beam.py --data data/en-fr/prepared --dicts data/en-fr/prepared --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt --output assignments/05/diversity/translations_standard.txt --cuda True --n 3\n",
            "[2022-12-13 09:09:22] Arguments: {'cuda': 'True', 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': None, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'log_file': None, 'save_dir': '/home/user/kew/HS2021/atmt/tests/assignment_03/baseline/checkpoints', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared', 'checkpoint_path': 'assignments/03/baseline/checkpoints/checkpoint_last.pt', 'output': 'assignments/05/diversity/translations_standard.txt', 'max_len': 100, 'beam_size': 5, 'alpha': 0.0, 'lmbda': 0.0, 'n': 3, 'gamma': 0.0}\n",
            "[2022-12-13 09:09:22] Loaded a source dictionary (fr) with 4000 words\n",
            "[2022-12-13 09:09:22] Loaded a target dictionary (en) with 4000 words\n",
            "[2022-12-13 09:09:25] Loaded a model from checkpoint assignments/03/baseline/checkpoints/checkpoint_last.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push to Repository"
      ],
      "metadata": {
        "id": "bRCj6itLMVvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nQS9fqSMRxx",
        "outputId": "9a25080c-7e89-4a87-ae48-d8e2040aa275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edymIRLl3JKz",
        "outputId": "759ac698-d274-4952-cf12-baa7e99d6799"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/miwytt/atmt_2022\n",
            "   8f952b2..b488d51  assignment05 -> origin/assignment05\n",
            "Updating 8f952b2..b488d51\n",
            "Fast-forward\n",
            " translate_beam.py | 8 \u001b[32m+++++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 5 insertions(+), 3 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout b488d5137d655fdee5623c1ad3b2feac68edea52"
      ],
      "metadata": {
        "id": "a-ZZrz4Y3KZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420feebb-8552-4f15-bf84-9dff5380eb3c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M\tmoses_scripts/detokenizer.perl\n",
            "M\tmoses_scripts/detruecase.perl\n",
            "Note: checking out 'b488d5137d655fdee5623c1ad3b2feac68edea52'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at b488d51 Update translate_beam.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "774prWREtGF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}